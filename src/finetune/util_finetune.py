import math
import os

from easydict import EasyDict
import torch
import numpy as np
import random

from typing import List, Optional
from collections import Counter

from itertools import chain
from torch.utils.data import Sampler, DataLoader, Dataset
from transformers import MODEL_MAPPING
from transformers.trainer_pt_utils import get_length_grouped_indices as get_length_grouped_indices_hf

from src.dataset import load_parquet_image_dataset

MODEL_CONFIG_CLASSES = list(MODEL_MAPPING.keys())
MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)
import torch.distributed as dist


def rank0_print(*args):
    if dist.is_initialized():
        if dist.get_rank() == 0:
            print(f"Rank {dist.get_rank()}: ", *args)
    else:
        print(*args)




# Set random seeds for reproducibility
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)




# Set random seeds for reproducibility
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)





def group_texts(examples, block_size=512):
    # Concatenate all texts.
    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}
    total_length = len(concatenated_examples[list(examples.keys())[0]])
    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can
    # customize this part to your needs.
    if total_length >= block_size:
        total_length = (total_length // block_size) * block_size
    # Split by chunks of max_len.
    result = {
        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]
        for k, t in concatenated_examples.items()
    }
    result["labels"] = result["input_ids"].copy()
    return result

# New Code #
def evaluate(training_args, model, eval_dataloader, accelerator, logger):
    # Sync after evaluation

    model.eval()
    losses = []
    for step, batch in enumerate(eval_dataloader):
        if accelerator.is_main_process:
            logger.info(f"||||Step {step + 1} / {len(eval_dataloader)} ||||")
        with torch.no_grad():
            outputs = model(**batch)

        loss = outputs.loss
        losses.append(accelerator.gather_for_metrics(loss.repeat(training_args.per_device_eval_batch_size)))

    losses = torch.cat(losses)


    try:
        eval_loss = torch.mean(losses)
        perplexity = math.exp(eval_loss)
    except OverflowError:
        perplexity = float("inf")
    return perplexity, eval_loss



def maybe_zero_3(param, ignore_status=False, name=None):
    from deepspeed import zero
    from deepspeed.runtime.zero.partition_parameters import ZeroParamStatus

    if hasattr(param, "ds_id"):
        if param.ds_status == ZeroParamStatus.NOT_AVAILABLE:
            if not ignore_status:
                print(name, "no ignore status")
        with zero.GatheredParameters([param]):
            param = param.data.detach().cpu().clone()
    else:
        param = param.detach().cpu().clone()
    return param


def get_mm_adapter_state_maybe_zero_3(named_params, keys_to_match):
    to_return = {k: t for k, t in named_params if any(key_match in k for key_match in keys_to_match)}
    to_return = {k: maybe_zero_3(v, ignore_status=True, name=k).cpu() for k, v in to_return.items()}
    return to_return


def split_to_even_chunks(indices, lengths, num_chunks):
    """
    Split a list of indices into `chunks` chunks of roughly equal lengths.
    """

    if len(indices) % num_chunks != 0:
        return [indices[i::num_chunks] for i in range(num_chunks)]

    num_indices_per_chunk = len(indices) // num_chunks

    chunks = [[] for _ in range(num_chunks)]
    chunks_lengths = [0 for _ in range(num_chunks)]
    for index in indices:
        shortest_chunk = chunks_lengths.index(min(chunks_lengths))
        chunks[shortest_chunk].append(index)
        chunks_lengths[shortest_chunk] += lengths[index]
        if len(chunks[shortest_chunk]) == num_indices_per_chunk:
            chunks_lengths[shortest_chunk] = float("inf")

    return chunks






def get_variable_length_grouped_indices(lengths, batch_size, world_size, megabatch_mult=8, generator=None):
    # We need to use torch for the random part as a distributed sampler will set the random seed for torch.
    indices = torch.randperm(len(lengths), generator=generator)
    sorted_indices = sorted(range(len(lengths)), key=lambda i: lengths[i], reverse=True)
    megabatch_size = world_size * batch_size * megabatch_mult
    megabatches = [sorted_indices[i : i + megabatch_size] for i in range(0, len(lengths), megabatch_size)]
    megabatches = [sorted(megabatch, key=lambda i: indices[i], reverse=True) for megabatch in megabatches]
    shuffled_indices = [i for megabatch in megabatches for i in megabatch]
    world_batch_size = world_size * batch_size
    batches = [shuffled_indices[i : i + world_batch_size] for i in range(0, len(lengths), world_batch_size)]
    batch_indices = torch.randperm(len(batches), generator=generator)
    batches = [batches[i] for i in batch_indices]

    return [i for batch in batches for i in batch]


def get_modality_length_grouped_indices(lengths, batch_size, world_size, generator=None):
    """
    Return a list of indices so that each slice of `batch_size` consecutive indices correspond to elements of similar
    lengths. To do this, the indices are:

    - randomly permuted
    - grouped in mega-batches of size `mega_batch_mult * batch_size`
    - reorder by length in each mega-batch

    The result is the concatenation of all mega-batches, with the batch of `batch_size` containing the element of
    maximum length placed first, so that an OOM happens sooner rather than later.
    """

    # Ensure all samples have non-zero length
    assert all(l != 0 for l in lengths), "Should not have zero length."
    # If all samples belong to a single modality (either all multimodal or all language-only), apply default grouping
    if all(l > 0 for l in lengths) or all(l < 0 for l in lengths):
        # all samples are in the same modality
        return get_length_grouped_indices(lengths, batch_size, world_size, generator=generator)
    # Separate indices and lengths of multimodal and language-only samples
    mm_indices, mm_lengths = zip(*[(i, l) for i, l in enumerate(lengths) if l > 0])
    lang_indices, lang_lengths = zip(*[(i, -l) for i, l in enumerate(lengths) if l < 0])

    # Perform length-based grouping and random shuffling for multimodal samples
    mm_shuffle = [mm_indices[i] for i in get_length_grouped_indices(mm_lengths, batch_size, world_size, generator=None)]
    # Perform length-based grouping and random shuffling for language-only samples
    lang_shuffle = [lang_indices[i] for i in get_length_grouped_indices(lang_lengths, batch_size, world_size, generator=None)]
    megabatch_size = world_size * batch_size
    mm_megabatches = [mm_shuffle[i : i + megabatch_size] for i in range(0, len(mm_shuffle), megabatch_size)]
    lang_megabatches = [lang_shuffle[i : i + megabatch_size] for i in range(0, len(lang_shuffle), megabatch_size)]

    # Prepare for optional merging of final smaller batches from each modality
    last_mm = mm_megabatches[-1]
    last_lang = lang_megabatches[-1]
    additional_batch = last_mm + last_lang
    # Combine all full megabatches from both modalities
    megabatches = mm_megabatches[:-1] + lang_megabatches[:-1]
    # Shuffle the megabatches to avoid ordering bias
    megabatch_indices = torch.randperm(len(megabatches), generator=generator)
    # Apply the random shuffling to the megabatches
    megabatches = [megabatches[i] for i in megabatch_indices]

    # Optionally add the remaining samples as a final megabatch
    if len(additional_batch) > 0:
        megabatches.append(sorted(additional_batch))

    return [i for megabatch in megabatches for i in megabatch]


def get_length_grouped_indices(lengths, batch_size, world_size, generator=None, merge=True):
    """
    Return a list of indices so that each slice of `batch_size` consecutive indices correspond to elements of similar
    lengths. To do this, the indices are:

    - randomly permuted
    - grouped in mega-batches of size `mega_batch_mult * batch_size`
    - reorder by length in each mega-batch

    The result is the concatenation of all mega-batches, with the batch of `batch_size` containing the element of
    maximum length placed first, so that an OOM happens sooner rather than later.
    """

    # We need to use torch for the random part as a distributed sampler will set the random seed for torch.
    indices = torch.randperm(len(lengths), generator=generator)
    megabatch_size = world_size * batch_size
    megabatches = [indices[i : i + megabatch_size].tolist() for i in range(0, len(lengths), megabatch_size)]
    megabatches = [sorted(megabatch, key=lambda i: lengths[i], reverse=True) for megabatch in megabatches]
    megabatches = [split_to_even_chunks(megabatch, lengths, world_size) for megabatch in megabatches]

    return [i for megabatch in megabatches for batch in megabatch for i in batch]


def get_length_grouped_indices_auto_single(lengths, batch_size, world_size, generator=None):
    indices = get_length_grouped_indices_hf(lengths, batch_size * world_size, generator=generator)

    megabatch_size = world_size * batch_size
    megabatches = [indices[i : i + megabatch_size] for i in range(0, len(lengths), megabatch_size)]
    megabatches = [sorted(megabatch, key=lambda i: lengths[i], reverse=True) for megabatch in megabatches]
    megabatches = [split_to_even_chunks(megabatch, lengths, world_size) for megabatch in megabatches]

    # We need to use torch for the random part as a distributed sampler will set the random seed for torch.
    batch_indices = torch.randperm(len(megabatches), generator=generator)
    megabatches = [megabatches[i] for i in batch_indices]

    return [i for megabatch in megabatches for batch in megabatch for i in batch]


def get_modality_length_grouped_indices_auto(lengths, batch_size, world_size, generator=None):
    # We need to use torch for the random part as a distributed sampler will set the random seed for torch.
    assert all(l != 0 for l in lengths), "Should not have zero length."
    if all(l > 0 for l in lengths) or all(l < 0 for l in lengths):
        # all samples are in the same modality
        return get_length_grouped_indices_auto_single(lengths, batch_size, world_size, generator=generator)
    mm_indices, mm_lengths = zip(*[(i, l) for i, l in enumerate(lengths) if l > 0])
    lang_indices, lang_lengths = zip(*[(i, -l) for i, l in enumerate(lengths) if l < 0])

    mm_shuffle = [mm_indices[i] for i in get_length_grouped_indices_auto_single(mm_lengths, batch_size, world_size, generator=None)]
    lang_shuffle = [lang_indices[i] for i in get_length_grouped_indices_auto_single(lang_lengths, batch_size, world_size, generator=None)]
    megabatch_size = world_size * batch_size
    mm_megabatches = [mm_shuffle[i : i + megabatch_size] for i in range(0, len(mm_shuffle), megabatch_size)]
    lang_megabatches = [lang_shuffle[i : i + megabatch_size] for i in range(0, len(lang_shuffle), megabatch_size)]

    last_mm = mm_megabatches[-1]
    last_lang = lang_megabatches[-1]
    additional_batch = last_mm + last_lang
    megabatches = mm_megabatches[:-1] + lang_megabatches[:-1]
    megabatch_indices = torch.randperm(len(megabatches), generator=generator)
    megabatches = [megabatches[i] for i in megabatch_indices]

    # FIXME: Hard code to avoid last batch mixed with different modalities
    # if len(additional_batch) > 0:
    #     megabatches.append(sorted(additional_batch))

    return [i for megabatch in megabatches for i in megabatch]


# class BlueprintGroupedSamplerv1(Sampler):
#     """
#     FIXED: Sampler that guarantees EXACTLY the same number of images per batch
#     across all GPUs for memory uniformity in distributed training.
#     """
#
#     def __init__(
#             self,
#             batch_size: int,
#             lengths: List[int],
#             n_images: List[int],
#             generator: Optional[torch.Generator] = None,
#             seed: int = 42,
#             drop_last: bool = True
#     ):
#         super().__init__(None)
#
#         self.batch_size = batch_size
#         self.lengths = lengths
#         self.n_images = n_images
#         self.drop_last = drop_last
#         self.generator = generator or torch.Generator().manual_seed(seed)
#         self.epoch = 0
#
#         # Validation
#         assert len(lengths) == len(n_images), "lengths and n_images must have same length"
#         assert all(n in [1, 2] for n in n_images), "n_images must contain only values 1 or 2"
#         assert batch_size > 0, "batch_size must be positive"
#
#         # Pre-compute indices by category
#         self.indices_1img = np.where(np.array(n_images) == 1)[0]
#         self.indices_2img = np.where(np.array(n_images) == 2)[0]
#
#         print(f"[BlueprintSampler] Dataset: {len(self.indices_1img)} samples with 1 image, {len(self.indices_2img)} samples with 2 images")
#
#         # Calculate and validate strategy
#         self.strategy = self._calculate_uniform_strategy()
#         self._validate_strategy()
#
#         print(f"[BlueprintSampler] Strategy for batch_size={batch_size}: {self.strategy}")
#
#     def _calculate_uniform_strategy(self):
#         """Calculate strategy that ensures EXACTLY batch_size images per GPU."""
#         target_images = self.batch_size
#
#         if target_images == 1:
#             return {
#                     "samples_1img"    : 1,
#                     "samples_2img"    : 0,
#                     "images_per_batch": 1,
#                     "description"     : "1 sample with 1 image"
#             }
#         elif target_images == 2:
#             return {
#                     "samples_1img"    : 1,
#                     "samples_2img"    : 0,
#                     "images_per_batch": 2,
#                     "description"     : "2 sample with 1 images"
#             }
#         elif target_images == 3:
#             return {
#                     "samples_1img"    : 1,
#                     "samples_2img"    : 2,
#                     "images_per_batch": 5,
#                     "description"     : "1 sample with 2 images + 2 sample with 1 image"
#             }
#         elif target_images == 4:
#             return {
#                     "samples_1img"    : 1,
#                     "samples_2img"    : 3,
#                     "images_per_batch": 7,
#                     "description"     : "1 samples with 1 images, 3 with 2 each"
#             }
#         else:
#             # General strategy
#             samples_2img = target_images // 2
#             samples_1img = target_images % 2
#
#             return {
#                     "samples_1img"    : samples_1img,
#                     "samples_2img"    : samples_2img,
#                     "images_per_batch": samples_2img * 2 + samples_1img,
#                     "description"     : f"{samples_2img} samples with 2 images + {samples_1img} samples with 1 image"
#             }
#
#     def _validate_strategy(self):
#         """Validate that our strategy is feasible and safe."""
#         strategy = self.strategy
#
#         required_1img = strategy["samples_1img"]
#         required_2img = strategy["samples_2img"]
#
#         if required_1img > 0 and len(self.indices_1img) < required_1img:
#             raise RuntimeError(
#                     f"Strategy requires {required_1img} samples with 1 image per batch, "
#                     f"but dataset only has {len(self.indices_1img)} such samples"
#             )
#
#         if required_2img > 0 and len(self.indices_2img) < required_2img:
#             raise RuntimeError(
#                     f"Strategy requires {required_2img} samples with 2 images per batch, "
#                     f"but dataset only has {len(self.indices_2img)} such samples"
#             )
#
#     def _build_uniform_batches(self, max_batches=None):
#         """Build batches with guaranteed uniform image count."""
#         strategy = self.strategy
#         samples_1img = strategy["samples_1img"]
#         samples_2img = strategy["samples_2img"]
#
#         # Deterministic shuffle
#         g = torch.Generator()
#         g.manual_seed(self.epoch + 42)
#
#         if len(self.indices_1img) > 0:
#             indices_1img_shuffled = self.indices_1img[torch.randperm(len(self.indices_1img), generator=g).numpy()]
#         else:
#             indices_1img_shuffled = np.array([])
#
#         if len(self.indices_2img) > 0:
#             indices_2img_shuffled = self.indices_2img[torch.randperm(len(self.indices_2img), generator=g).numpy()]
#         else:
#             indices_2img_shuffled = np.array([])
#
#         # Calculate maximum batches
#         max_batches_1img = len(indices_1img_shuffled) // samples_1img if samples_1img > 0 else float('inf')
#         max_batches_2img = len(indices_2img_shuffled) // samples_2img if samples_2img > 0 else float('inf')
#         if max_batches_2img == float('inf') or max_batches_1img == float('inf'):
#             max_batches = min(max_batches_2img, max_batches_1img)
#
#             remaining = 0
#         else:
#             max_batches = min(max_batches_2img, max_batches_1img)
#             min_batches = max(max_batches_2img, max_batches_1img)
#             remaining = abs(max_batches - min_batches)
#
#         if max_batches == 0:
#             raise RuntimeError(
#                     f"Cannot create any complete batches with strategy {strategy}. "
#                     f"Available: {len(self.indices_1img)} 1-img, {len(self.indices_2img)} 2-img. "
#                     f"Required per batch: {samples_1img} 1-img, {samples_2img} 2-img."
#             )
#
#         # Build validated batches
#         batches = []
#         for batch_idx in range(max_batches):
#             batch = []
#
#             # Add 2-image samples
#             if samples_2img > 0:
#                 start_2img = batch_idx * samples_2img
#                 end_2img = start_2img + samples_2img
#                 if end_2img <= len(indices_2img_shuffled):
#                     batch.extend(indices_2img_shuffled[start_2img:end_2img])
#
#             # Add 1-image samples
#             if samples_1img > 0:
#                 start_1img = batch_idx * samples_1img
#                 end_1img = start_1img + samples_1img
#                 if end_1img <= len(indices_1img_shuffled):
#                     batch.extend(indices_1img_shuffled[start_1img:end_1img])
#
#             # Validate batch
#             if len(batch) != self.batch_size:
#                 continue
#
#             total_images = sum(2 if idx in self.indices_2img else 1 for idx in batch)
#             batches.append(batch)
#         # Do the remaining batches
#         for batch_idx in range(remaining// self.batch_size):
#             batch = []
#             # find who is remaining
#             # Add 2-image samples
#             if not max_batches_2img == max_batches:
#                 start_2img = batch_idx * samples_2img
#                 end_2img = start_2img + samples_2img
#                 if end_2img <= len(indices_2img_shuffled):
#                     batch.extend(indices_2img_shuffled[start_2img:end_2img])
#
#             # Add 1-image samples
#             if not max_batches_1img == max_batches:
#                 # If we are here, we have to add 1-image samples for the amount of batch size
#                 start_1img = batch_idx * samples_1img
#                 end_1img = start_1img + samples_1img
#                 if end_1img <= len(indices_1img_shuffled):
#                     batch.extend(indices_1img_shuffled[start_1img:end_1img])
#
#             # Validate batch
#             if len(batch) != self.batch_size:
#                 continue
#
#             total_images = sum(2 if idx in self.indices_2img else 1 for idx in batch)
#             if total_images != self.batch_size:
#                 raise RuntimeError(f"Batch {batch_idx} has {total_images} images, expected {self.batch_size}")
#
#             batches.append(batch)
#
#         return batches
#
#     def __iter__(self):
#         batches = self._build_uniform_batches()
#         indices = []
#         for batch in batches:
#             indices.extend(batch)
#         return iter(indices)
#
#     def __len__(self):
#         try:
#             batches = self._build_uniform_batches()
#             return len(batches) * self.batch_size
#         except RuntimeError:
#             return 0
#
#     def set_epoch(self, epoch: int):
#         self.epoch = epoch
#
#     def get_memory_info(self):
#         """Report expected memory usage."""
#         strategy = self.strategy
#         return {
#                 "images_per_batch"    : strategy["images_per_batch"],
#                 "samples_per_batch"   : self.batch_size,
#                 "strategy_description": strategy["description"],
#                 "memory_uniformity"   : "GUARANTEED" if strategy["images_per_batch"] == self.batch_size else "VIOLATED"
#         }


class BlueprintGroupedSampler(Sampler):
    """
    Sampler che garantisce uniformitÃ  nel numero di immagini per batch,
    compatibile con Accelerate (non fa sharding manuale).

    Strategia:
    - Bilancia campioni con 1-2 immagini per mantenere memoria uniforme
    - Lascia ad Accelerate la gestione del distributed training
    - Mantiene determinismo per reproducibilitÃ 
    """

    def __init__(
            self,
            batch_size: int,
            lengths: List[int],
            n_images: List[int],
            generator: Optional[torch.Generator] = None,
            seed: int = 42,
            drop_last: bool = True
    ):
        super().__init__(None)

        # Parametri base - NON moltiplicare per world_size
        self.batch_size = batch_size  # batch size per device
        self.lengths = lengths
        self.n_images = n_images
        self.drop_last = drop_last
        self.generator = generator or torch.Generator().manual_seed(seed)
        self.epoch = 0

        # Validazione input
        assert len(lengths) == len(n_images), "lengths e n_images devono avere la stessa lunghezza"
        assert all(n in [1, 2] for n in n_images), "n_images deve contenere solo valori 1 o 2"

        # Pre-computa gli indici per categoria
        self.indices_1img = np.where(np.array(n_images) == 1)[0]
        self.indices_2img = np.where(np.array(n_images) == 2)[0]

        print(f"[BlueprintSampler] Dataset: {len(self.indices_1img)} campioni 1-img, {len(self.indices_2img)} campioni 2-img")

        # Calcola strategia di sampling basata su batch_size
        self.sampling_strategy = self._calculate_sampling_strategy()
        print(f"[BlueprintSampler] Strategia per batch_size={batch_size}: {self.sampling_strategy}")

    def _calculate_sampling_strategy(self):
        """
        Calcola quanti campioni 1-img e 2-img usare per batch
        per mantenere carico di memoria uniforme.
        """
        if self.batch_size == 1:
            # Con batch_size=1, alternare tra 1-img e 2-img
            return {"samples_1img": 1, "samples_2img": 0, "images_per_batch": 1}
        elif self.batch_size == 2:
            # Strategia: 1 campione 2-img = 2 immagini totali
            return {"samples_1img": 0, "samples_2img": 1, "images_per_batch": 2}
        elif self.batch_size == 4:
            # Strategia: 3 campioni 2-img + 1 campione 1-img = 7 immagini totali
            return {"samples_1img": 1, "samples_2img": 3, "images_per_batch": 7}
        else:
            # Strategia generale: cerca bilanciamento ottimale
            # PrioritÃ  ai campioni 2-img per efficienza memoria
            samples_2img = min(self.batch_size, self.batch_size // 2 + 1)
            samples_1img = self.batch_size - samples_2img
            images_per_batch = samples_2img * 2 + samples_1img
            return {
                    "samples_1img"    : samples_1img,
                    "samples_2img"    : samples_2img,
                    "images_per_batch": images_per_batch
            }

    def _build_balanced_batches(self):
        """
        Costruisce batch bilanciati con numero uniforme di immagini.
        """
        strategy = self.sampling_strategy
        samples_1img = strategy["samples_1img"]
        samples_2img = strategy["samples_2img"]

        # Shuffle deterministico per epoch
        g = torch.Generator()
        g.manual_seed(self.epoch + 42)

        # Shuffle degli indici per categoria
        indices_1img_shuffled = self.indices_1img[torch.randperm(len(self.indices_1img), generator=g).numpy()]
        indices_2img_shuffled = self.indices_2img[torch.randperm(len(self.indices_2img), generator=g).numpy()]

        # Calcola numero massimo di batch possibili
        max_batches_1img = len(indices_1img_shuffled) // samples_1img if samples_1img > 0 else float('inf')
        max_batches_2img = len(indices_2img_shuffled) // samples_2img if samples_2img > 0 else float('inf')
        max_batches = min(max_batches_1img, max_batches_2img)

        if max_batches == 0:
            print(f"âš ï¸ [BlueprintSampler] Impossibile creare batch con strategia {strategy}")
            return []

        # Costruisce i batch
        batches = []
        for batch_idx in range(max_batches):
            batch = []

            # Aggiungi campioni 2-img
            start_2img = batch_idx * samples_2img
            end_2img = start_2img + samples_2img
            if samples_2img > 0 and end_2img <= len(indices_2img_shuffled):
                batch.extend(indices_2img_shuffled[start_2img:end_2img])

            # Aggiungi campioni 1-img
            start_1img = batch_idx * samples_1img
            end_1img = start_1img + samples_1img
            if samples_1img > 0 and end_1img <= len(indices_1img_shuffled):
                batch.extend(indices_1img_shuffled[start_1img:end_1img])

            # Verifica dimensione batch
            if len(batch) == self.batch_size:
                batches.append(batch)
            elif not self.drop_last and len(batch) > 0:
                # Padding se necessario e drop_last=False
                while len(batch) < self.batch_size:
                    batch.append(batch[0])  # Replica primo elemento
                batches.append(batch)

        print(f"[BlueprintSampler] Creati {len(batches)} batch per epoch {self.epoch}")

        return batches

    def __iter__(self):
        """Iteratore che restituisce gli indici per l'epoch corrente."""
        batches = self._build_balanced_batches()

        # Flatten dei batch in sequenza lineare per DataLoader
        indices = []
        for batch in batches:
            indices.extend(batch)

        return iter(indices)

    def __len__(self):
        """Numero totale di campioni (non batch)."""
        batches = self._build_balanced_batches()
        return len(batches) * self.batch_size

    def set_epoch(self, epoch: int):
        """Imposta l'epoch per shuffle deterministic."""
        self.epoch = epoch

#
# class BlueprintGroupedSampler(Sampler):
#     """
#     CORRECTED: Sampler that guarantees a FIXED number of images per batch
#     regardless of sample composition. For batch_size=4, always produces 7 images.
#
#     Strategy Adaptation:
#     - Primary: 3 samples Ã— 2 images + 1 sample Ã— 1 image = 7 images
#     - Fallback: 7 samples Ã— 1 image = 7 images (when 2-img samples run out)
#     """
#
#     def __init__(
#             self,
#             batch_size: int,
#             lengths: List[int],
#             n_images: List[int],
#             generator: Optional[torch.Generator] = None,
#             seed: int = 42,
#             drop_last: bool = True
#     ):
#         super().__init__(None)
#
#         self.batch_size = batch_size
#         self.lengths = lengths
#         self.n_images = n_images
#         self.drop_last = drop_last
#         self.generator = generator or torch.Generator().manual_seed(seed)
#         self.epoch = 0
#
#         # Validation
#         assert len(lengths) == len(n_images), "lengths and n_images must have same length"
#         assert all(n in [1, 2] for n in n_images), "n_images must contain only values 1 or 2"
#         assert batch_size > 0, "batch_size must be positive"
#
#         # Pre-compute indices by category
#         self.indices_1img = np.where(np.array(n_images) == 1)[0]
#         self.indices_2img = np.where(np.array(n_images) == 2)[0]
#
#         print(f"[BlueprintSampler] Dataset: {len(self.indices_1img)} samples with 1 image, {len(self.indices_2img)} samples with 2 images")
#
#         # Calculate FIXED image target and strategies
#         self.target_images = self._get_target_images()
#         self.primary_strategy = self._calculate_primary_strategy()
#         self.fallback_strategy = self._calculate_fallback_strategy()
#
#         self._validate_strategies()
#
#         print(f"[BlueprintSampler] Target images per batch: {self.target_images}")
#         print(f"[BlueprintSampler] Primary strategy: {self.primary_strategy}")
#         print(f"[BlueprintSampler] Fallback strategy: {self.fallback_strategy}")
#
#     def _get_target_images(self):
#         """
#         Define the FIXED number of images per batch for each batch_size.
#         Must be achievable with exactly batch_size samples.
#         """
#         # For each batch_size, find the maximum achievable images
#         # Formula: max_images = batch_size * 2 (all 2-img samples)
#         # But we need a strategy that's robust to sample scarcity
#
#         if self.batch_size == 1:
#             return 2  # 1 sample Ã— 2 images (or fallback to 1Ã—1img if needed)
#         elif self.batch_size == 2:
#             return 3  # 1 sample Ã— 2 images + 1 sample Ã— 1 image
#         elif self.batch_size == 4:
#             return 7  # 3 samples Ã— 2 images + 1 sample Ã— 1 image = 7 images
#         elif self.batch_size == 8:
#             return 14  # 7 samples Ã— 2 images = 14 images (or fallback: 6Ã—2img + 2Ã—1img = 14)
#         else:
#             # General rule: try to maximize images while keeping strategies feasible
#             # Target around 1.5-1.75x batch_size
#             return max(self.batch_size, int(self.batch_size * 1.6))
#
#     def _calculate_primary_strategy(self):
#         """Calculate the preferred strategy using both 1-img and 2-img samples."""
#         target = self.target_images
#
#         # Special cases with exact strategies
#         if self.batch_size == 1 and target == 2:
#             return {
#                     "samples_1img"    : 0,
#                     "samples_2img"    : 1,
#                     "images_per_batch": 2,
#                     "description"     : "1 sample with 2 images"
#             }
#         elif self.batch_size == 2 and target == 3:
#             return {
#                     "samples_1img"    : 1,
#                     "samples_2img"    : 1,
#                     "images_per_batch": 3,
#                     "description"     : "1 sample with 2 images + 1 sample with 1 image"
#             }
#         elif self.batch_size == 4 and target == 7:
#             return {
#                     "samples_1img"    : 1,
#                     "samples_2img"    : 3,
#                     "images_per_batch": 7,
#                     "description"     : "3 samples with 2 images + 1 sample with 1 image"
#             }
#         elif self.batch_size == 8 and target == 14:
#             return {
#                     "samples_1img"    : 2,
#                     "samples_2img"    : 6,
#                     "images_per_batch": 14,
#                     "description"     : "6 samples with 2 images + 2 samples with 1 image"
#             }
#
#         # General strategy - find valid combination that uses batch_size samples for target images
#         for samples_2img in range(self.batch_size + 1):
#             samples_1img = self.batch_size - samples_2img
#             if samples_1img < 0:
#                 continue
#
#             total_images = samples_2img * 2 + samples_1img
#             if total_images == target:
#                 return {
#                         "samples_1img"    : samples_1img,
#                         "samples_2img"    : samples_2img,
#                         "images_per_batch": total_images,
#                         "description"     : f"{samples_2img} samples with 2 images + {samples_1img} samples with 1 image"
#                 }
#
#         # If no combination works, this target is impossible for this batch_size
#         raise ValueError(
#                 f"Cannot create strategy for batch_size={self.batch_size} with target={target} images. "
#                 f"No valid combination exists."
#         )
#
#     def _calculate_fallback_strategy(self):
#         """Calculate fallback strategy when primary strategy can't be used."""
#         target = self.target_images
#
#         # For fallback, we need to fit exactly target_images in batch_size samples
#         # This requires finding a valid combination of 1-img and 2-img samples
#
#         # Try different combinations to achieve exactly target images
#         for samples_2img in range(self.batch_size + 1):
#             samples_1img = self.batch_size - samples_2img
#             if samples_1img < 0:
#                 continue
#
#             total_images = samples_2img * 2 + samples_1img
#             if total_images == target:
#                 return {
#                         "samples_1img"    : samples_1img,
#                         "samples_2img"    : samples_2img,
#                         "images_per_batch": total_images,
#                         "description"     : f"{samples_2img} samples with 2 images + {samples_1img} samples with 1 image"
#                 }
#
#         # If no exact combination exists, this batch_size/target combination is impossible
#         raise ValueError(
#                 f"Cannot create fallback strategy for batch_size={self.batch_size} "
#                 f"with target={target} images. No valid combination of 1-img and 2-img samples exists."
#         )
#
#     def _validate_strategies(self):
#         """Validate that both strategies produce the target image count."""
#         # Validate primary strategy
#         if self.primary_strategy["images_per_batch"] != self.target_images:
#             raise ValueError(
#                     f"Primary strategy produces {self.primary_strategy['images_per_batch']} images, "
#                     f"but target is {self.target_images} images"
#             )
#
#         # Validate fallback strategy
#         if self.fallback_strategy["images_per_batch"] != self.target_images:
#             raise ValueError(
#                     f"Fallback strategy produces {self.fallback_strategy['images_per_batch']} images, "
#                     f"but target is {self.target_images} images"
#             )
#
#         # Validate sample counts don't exceed batch_size
#         for strategy_name, strategy in [("Primary", self.primary_strategy), ("Fallback", self.fallback_strategy)]:
#             total_samples = strategy["samples_1img"] + strategy["samples_2img"]
#             if total_samples != self.batch_size:
#                 raise ValueError(
#                         f"{strategy_name} strategy uses {total_samples} samples, "
#                         f"but batch_size is {self.batch_size}"
#                 )
#
#     def _build_adaptive_batches(self):
#         """
#         Build batches with adaptive strategy switching while maintaining target image count.
#         """
#         # Deterministic shuffle
#         g = torch.Generator()
#         g.manual_seed(self.epoch + 42)
#
#         # Shuffle indices for each category
#         if len(self.indices_1img) > 0:
#             indices_1img_shuffled = self.indices_1img[torch.randperm(len(self.indices_1img), generator=g).numpy()]
#         else:
#             indices_1img_shuffled = np.array([])
#
#         if len(self.indices_2img) > 0:
#             indices_2img_shuffled = self.indices_2img[torch.randperm(len(self.indices_2img), generator=g).numpy()]
#         else:
#             indices_2img_shuffled = np.array([])
#
#         batches = []
#         idx_1img = 0
#         idx_2img = 0
#         batch_count = 0
#
#         # Try primary strategy first, then switch to fallback when needed
#         current_strategy = self.primary_strategy
#         strategy_switches = 0
#         switched_to_fallback = False
#
#         while True:
#             samples_1img_needed = current_strategy["samples_1img"]
#             samples_2img_needed = current_strategy["samples_2img"]
#
#             # Check if we have enough samples for current strategy
#             can_use_current = (
#                     idx_1img + samples_1img_needed <= len(indices_1img_shuffled) and
#                     idx_2img + samples_2img_needed <= len(indices_2img_shuffled)
#             )
#
#             # If primary strategy fails and we haven't switched yet, switch to fallback
#             if not can_use_current and current_strategy == self.primary_strategy and not switched_to_fallback:
#                 current_strategy = self.fallback_strategy
#                 strategy_switches += 1
#                 switched_to_fallback = True
#                 print(f"[BlueprintSampler] Switching to fallback strategy at batch {batch_count}")
#
#                 # Re-check with fallback strategy
#                 samples_1img_needed = current_strategy["samples_1img"]
#                 samples_2img_needed = current_strategy["samples_2img"]
#                 can_use_current = (
#                         idx_1img + samples_1img_needed <= len(indices_1img_shuffled) and
#                         idx_2img + samples_2img_needed <= len(indices_2img_shuffled)
#                 )
#
#             # If we still can't use current strategy (including fallback), we're done
#             if not can_use_current:
#                 break
#
#             # Build batch using current strategy
#             batch = []
#
#             # Add 2-image samples
#             for _ in range(samples_2img_needed):
#                 if idx_2img < len(indices_2img_shuffled):
#                     batch.append(indices_2img_shuffled[idx_2img])
#                     idx_2img += 1
#                 else:
#                     # This shouldn't happen if our logic is correct
#                     print(f"âš ï¸ Ran out of 2-image samples at batch {batch_count}")
#                     break
#
#             # Add 1-image samples
#             for _ in range(samples_1img_needed):
#                 if idx_1img < len(indices_1img_shuffled):
#                     batch.append(indices_1img_shuffled[idx_1img])
#                     idx_1img += 1
#                 else:
#                     # This shouldn't happen if our logic is correct
#                     print(f"âš ï¸ Ran out of 1-image samples at batch {batch_count}")
#                     break
#
#             # Validate batch composition
#             if len(batch) != self.batch_size:
#                 print(f"âš ï¸ Incomplete batch {batch_count}: {len(batch)} samples, expected {self.batch_size}")
#                 break
#
#             # Validate image count (CRITICAL)
#             total_images = sum(2 if idx in self.indices_2img else 1 for idx in batch)
#             if total_images != self.target_images:
#                 raise RuntimeError(
#                         f"Batch {batch_count} has {total_images} images, expected exactly {self.target_images}. "
#                         f"Strategy: {current_strategy['description']}"
#                 )
#
#             batches.append(batch)
#             batch_count += 1
#
#             # Safety check to prevent infinite loops
#             if batch_count > 1000:  # Reasonable upper limit
#                 print(f"âš ï¸ Safety break: created {batch_count} batches, stopping to prevent infinite loop")
#                 break
#
#         print(f"[BlueprintSampler] Created {len(batches)} batches for epoch {self.epoch}")
#         if strategy_switches > 0:
#             print(f"[BlueprintSampler] Strategy switches: {strategy_switches}")
#         print(f"[BlueprintSampler] Each batch: {self.target_images} images guaranteed")
#
#         return batches
#
#     def __iter__(self):
#         """Iterator that returns indices for the current epoch."""
#         batches = self._build_adaptive_batches()
#         indices = []
#         for batch in batches:
#             indices.extend(batch)
#         return iter(indices)
#
#     def __len__(self):
#         """Total number of samples that will be processed."""
#         try:
#             batches = self._build_adaptive_batches()
#             return len(batches) * self.batch_size
#         except Exception:
#             return 0
#
#     def set_epoch(self, epoch: int):
#         """Set epoch for deterministic shuffling."""
#         self.epoch = epoch
#
#     def get_memory_info(self):
#         """Report expected memory usage."""
#         return {
#                 "target_images"    : self.target_images,
#                 "batch_size"       : self.batch_size,
#                 "primary_strategy" : self.primary_strategy["description"],
#                 "fallback_strategy": self.fallback_strategy["description"],
#                 "memory_pattern"   : f"Always {self.target_images} images per batch"
#         }


class FakeVisionDataset(Dataset):
    """Fake dataset for testing with varying image counts and lengths."""

    def __init__(self, n_images=None, lenghts=None):
        # Generate fake data with controlled distribution
        self.data = []
        for i in range(len(n_images)):
            self.data.append({
                    'id'         : i,
                    'n_images'   : n_images[i],
                    'length'     : lenghts[i],
                    'fake_text'  : f"Sample {i} with {n_images[i]} images and {lenghts[i]} tokens",
                    'fake_images': [f"image_{i}_{j}.jpg" for j in range(n_images[i])]
            })
    def __len__(self):
        return self.data.__len__()

    def __getitem__(self, idx):
        return self.data[idx]


def analyze_dataset_distribution(dataset):
    """Analyze the distribution of image counts and lengths."""
    n_images = [item['n_images'] for item in dataset.data]
    lengths = [item['length'] for item in dataset.data]

    print("=" * 70)
    print("DATASET DISTRIBUTION ANALYSIS")
    print("=" * 70)

    # Image count distribution
    img_dist = Counter(n_images)
    print(f"Image count distribution:")
    for count, freq in sorted(img_dist.items()):
        print(f"  {count} image(s): {freq} samples ({freq / len(dataset) * 100:.1f}%)")

    # Length statistics
    lengths_1img = [l for l, n in zip(lengths, n_images) if n == 1]
    lengths_2img = [l for l, n in zip(lengths, n_images) if n == 2]

    print(f"\nLength statistics:")
    if lengths_1img:
        print(f"  1-image samples: mean={np.mean(lengths_1img):.1f}, std={np.std(lengths_1img):.1f}")
    if lengths_2img:
        print(f"  2-image samples: mean={np.mean(lengths_2img):.1f}, std={np.std(lengths_2img):.1f}")
    print(f"  Overall: mean={np.mean(lengths):.1f}, std={np.std(lengths):.1f}")

def load_and_prepare_datasets(data_args):
    """Load and prepare the datasets."""
    if data_args.dataset_dir is not None:
        if os.path.exists(data_args.dataset_dir + '_tok'):
            data_args.dataset_dir = data_args.dataset_dir + '_tok'
        else:
            raise ValueError('The dataset directory does not exist in tok version. Please create the format_code.')

        raw_datasets = load_parquet_image_dataset(
                dataset_dir=data_args.dataset_dir,
                split_list=["train", "val"],
                cache_dir=data_args.cache_dir,
                keep_in_memory=True,
                num_proc=data_args.preprocessing_num_workers,
        )

        if data_args.data_debug:
            # Reduce the dataset size for debugging purposes
            for split in raw_datasets.keys():
                raw_datasets[split] = raw_datasets[split].select(range(500))

    elif data_args.dataset_name is None:
        raise ValueError(
                "You need to specify either a dataset name or a dataset directory. "
                "Use --dataset_name for a HF dataset or --dataset_dir to specify the dataset folder in local (parquet)."
        )

    return raw_datasets["train"], raw_datasets["val"]



def test_adaptive_sampler(dataset):
    """Test the adaptive sampler with different batch sizes."""
    lengths = [item['length'] for item in dataset.data]
    n_images = [item['n_images'] for item in dataset.data]

    batch_sizes_to_test = [4, 8]

    print("\n" + "=" * 80)
    print("ADAPTIVE BLUEPRINT SAMPLER TESTING")
    print("=" * 80)

    results = {}

    for batch_size in batch_sizes_to_test:
        print(f"\nðŸŽ¯ Testing batch_size={batch_size}")
        print("-" * 50)

        try:
            # First, let's debug what target and strategies should be
            print(f"Debug: Calculating target images for batch_size={batch_size}")

            # Manual calculation to debug
            if batch_size == 1:
                target = 1
            elif batch_size == 2:
                target = 3
            elif batch_size == 4:
                target = 7
            elif batch_size == 8:
                target = 13

            print(f"Expected target: {target} images")

            # Debug valid combinations
            print("Valid combinations for this batch_size:")
            valid_combinations = []
            for samples_2img in range(batch_size + 1):
                samples_1img = batch_size - samples_2img
                if samples_1img >= 0:
                    total_images = samples_2img * 2 + samples_1img
                    if total_images <= target:
                        valid_combinations.append((samples_2img, samples_1img, total_images))
                        print(f"  {samples_2img}Ã—2img + {samples_1img}Ã—1img = {total_images} images")

            # Find combinations that match our target
            matching = [combo for combo in valid_combinations if combo[2] == target]
            print(f"Combinations matching target {target}: {matching}")

            if not matching:
                print(f"âš ï¸ No valid combinations for batch_size={batch_size}, target={target}")
                print(f"Available totals: {[combo[2] for combo in valid_combinations]}")
                # Adjust target to nearest feasible
                feasible_targets = [combo[2] for combo in valid_combinations]
                target = min(feasible_targets, key=lambda x: abs(x - target))
                print(f"Adjusting target to nearest feasible: {target}")

            sampler = BlueprintGroupedSampler(
                    batch_size=batch_size,
                    lengths=lengths,
                    n_images=n_images,
                    seed=42
            )

            # Test with DataLoader
            dataloader = DataLoader(
                    dataset,
                    sampler=sampler,
                    batch_size=batch_size,
                    collate_fn=lambda x: x
            )




            # Analyze batches
            batch_image_counts = []
            batch_sample_counts = []
            strategy_usage = {"primary": 0, "fallback": 0}

            for i, batch in enumerate(dataloader):
                total_images = sum(item['n_images'] for item in batch)
                if total_images != target:
                    print(f"Batch {i}: {len(batch)} samples, {total_images} images")
                batch_image_counts.append(total_images)
                batch_sample_counts.append(len(batch))

                # Determine which strategy was used
                count_1img = sum(1 for item in batch if item['n_images'] == 1)
                count_2img = sum(1 for item in batch if item['n_images'] == 2)

                print(f"Batch {i}: {len(batch)} samples, {total_images} images")
                print(f"  Batch {i}: {count_2img}Ã—2img + {count_1img}Ã—1img = {total_images} images total")

            # Validate results
            unique_image_counts = set(batch_image_counts)
            uniform_images = len(unique_image_counts) == 1


            results[batch_size] = {
                    'uniform_images': uniform_images,
                    'actual_images' : list(unique_image_counts),
                    'strategy_usage': strategy_usage,
                    'total_batches' : len(batch_image_counts)
            }

        except Exception as e:
            print(f"âŒ FAILED: {e}")
            import traceback
            traceback.print_exc()
            results[batch_size] = {
                    'error'         : str(e),
                    'uniform_images': False,
                    'correct_target': False
            }

    return results


def demonstrate_strategy_switching(dataset):
    """Demonstrate adaptive strategy switching when 2-img samples run out."""
    print("\n" + "=" * 70)
    print("STRATEGY SWITCHING DEMONSTRATION")
    print("=" * 70)

    # Create a dataset with limited 2-image samples to force switching
    limited_2img_data = []
    count_1img = 0
    count_2img = 0

    for item in dataset:
        if item['n_images'] == 2 and count_2img < 10:  # Only 10 2-image samples
            limited_2img_data.append(item)
            count_2img += 1
        elif item['n_images'] == 1 and count_1img < 100:  # Many 1-image samples
            limited_2img_data.append(item)
            count_1img += 1

    print(f"Limited dataset: {count_1img} 1-image samples, {count_2img} 2-image samples")

    lengths = [item['length'] for item in limited_2img_data]
    n_images = [item['n_images'] for item in limited_2img_data]

    # Test with batch_size=4 (should switch from primary to fallback)
    sampler = BlueprintGroupedSampler(
            batch_size=4,
            lengths=lengths,
            n_images=n_images,
            seed=42
    )

    # Create a simple dataset wrapper
    class LimitedDataset(Dataset):
        def __init__(self, data):
            self.data = data

        def __len__(self):
            return len(self.data)

        def __getitem__(self, idx):
            return self.data[idx]

    limited_dataset = LimitedDataset(limited_2img_data)
    dataloader = DataLoader(
            limited_dataset,
            sampler=sampler,
            batch_size=4,
            collate_fn=lambda x: x
    )

    print(f"\nBatch composition analysis:")
    for i, batch in enumerate(dataloader):
        if i >= 10:  # First 10 batches
            break

        count_1img = sum(1 for item in batch if item['n_images'] == 1)
        count_2img = sum(1 for item in batch if item['n_images'] == 2)
        total_images = count_1img + count_2img * 2

        strategy_type = "PRIMARY" if count_2img == 3 else "FALLBACK"
        print(f"  Batch {i}: {count_2img}Ã—2img + {count_1img}Ã—1img = {total_images} images ({strategy_type})")


if __name__ == "__main__":
    print("ðŸŽ¯ ADAPTIVE BLUEPRINTGROUPEDSAMPLER DEMONSTRATION")
    print("=" * 80)
    print("Key Feature: FIXED image count per batch with adaptive strategy switching")
    print("Example: batch_size=4 â†’ ALWAYS 7 images per batch")
    print("  â€¢ Primary: 3Ã—2img + 1Ã—1img = 7 images")
    print("  â€¢ Fallback: 7Ã—1img = 7 images (when 2-img samples run out)")
    print("=" * 80)

    # Create fake dataset
    print("\nðŸ“Š Creating fake dataset with 1000 samples...")
    CACHE_DIR = os.path.join(os.getcwd(), "hf_models_cache")

    data_args = dict(
            dataset_dir="/Users/filruff/Desktop/PHD/PROGETTI/Deep-Sick/data_chexinstruct/hf_parquet_gemma_format/gemma_3_findings",
            cache_dir=CACHE_DIR,
            data_debug=False,
            preprocessing_num_workers=1,
    )
    data_args = EasyDict(data_args)

    dataset, _ = load_and_prepare_datasets(data_args)
    # CREATE A DATASET FAKE WITH THE SAME STRUCTURE AND CONTENTS OF dataset
    dataset = FakeVisionDataset(n_images=dataset['n_of_images'], lenghts=dataset['length'])
    """Test the adaptive sampler with different batch sizes."""

    # Analyze dataset
    analyze_dataset_distribution(dataset)

    # Test adaptive sampler
    results = test_adaptive_sampler(dataset)

    # Demonstrate strategy switching
    demonstrate_strategy_switching(dataset)

    # Final summary
    print("\n" + "=" * 80)
    print("ðŸŽ¯ ADAPTIVE SAMPLER SUMMARY")
    print("=" * 80)

    for bs, result in results.items():

        if 'target_images' in result:
            target = result['target_images']
            success = result['uniform_images'] and result['correct_target']
            status = "âœ… SUCCESS" if success else "âŒ FAILED"
            print(f"Batch size {bs}: Target {target} images â†’ {status}")

            if success and 'strategy_usage' in result:
                usage = result['strategy_usage']
                print(f"  Strategy usage: {usage['primary']} primary + {usage['fallback']} fallback batches")

    print(f"\nðŸ”‘ Key Benefits:")
    print(f"   â€¢ GUARANTEED fixed image count per batch (e.g., always 7 for batch_size=4)")
    print(f"   â€¢ Adaptive strategy switching when sample types run out")
    print(f"   â€¢ No dangerous fallbacks that cause memory explosions")
    print(f"   â€¢ Predictable memory usage throughout training")
    print(f"\nðŸš€ This solves your CUDA OOM issue by maintaining constant memory load!")
#
